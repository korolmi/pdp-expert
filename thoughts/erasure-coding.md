# HDFS Erasure Coding 

Появилось относительно недавно - Hadoop 3.2.1 (проверить точнее).

## Идея 

Идея проста: вместо дорогой репликации использовать идею из RAID - для каждого блока данных файла (здесь они его назвают ''cell'') рассчитываем и храним блоки с контрольными суммами (один или несколько блоков). Тогда потеря одного или нескольких блоков не приведет к потере файла.

Самый простой способ - ''XOR'': для трех (например) блоков храним их XOR в виде отдельного блока. Тогда потеря любого одного блока позволит нам тем не менее прочитать исходную информацию (=восстановить потерянный блок). Проблема XOR - можем потерять не более одного блока.

Более сложный алгоритм - алгоритм ''Reed-Solomon (RS)''. Не углубляясь в подробности, он позволяет для K блоков данных рассчитать M блоков четности так, чтобы можно было избежать потерь данных при потере любых M блоков. Именно он в настоящее время используется в HDFS.

Как это выглядит:

{{ :datalake:er_coding_1.png |}}

Потеря дисков и восстановление

{{ :datalake:er_coding_2.png |}}

Теоретически (наверное) возможно множество вариантов (конфигураций) реализации EC схем, на практике (в Hadoop) их не так много

{{ :datalake:er_coding_3.png |}}

Здесь:

* первая цифра: сколько блоков используется для расчета контрольных сумм
* вторая цифра: сколько блоков контрольных сумм будет создано
* RS в начале: это т.н. "кодек" (в данном случае и пока только Reed-Solomon)

## Hadoop HDFS

При использовании EC нет необходимости в репликации (точнее - ее нет и быть не может, фактор репликации для EC файлов всегда 1 и не может быть изменен). То есть мы либо используем репликацию, либо EC.

На практике мы должны явно задать т.н. "политику" для файла или директории (при его создании), т.е. без явных действий никаких EC файлов и директорий не создастся.

В конфигурации можно задать политику по умолчанию - она будет использоваться в случаях, когда политика явно не задана (можно сказать setPolicy и не указать политику - будет использована политика по умолчанию).

Вообще реалиация EC повлекла за собой определенные изменения (см. документы в ссылках ниже), пока в нашем кластере мы ее не используем.

## Дополнительная информация

Ссылки

* https://hadoop.apache.org/docs/r3.2.1/hadoop-project-dist/hadoop-hdfs/HDFSErasureCoding.html
* https://docs.arenadata.io/adh/administration/hdfs/ErasureCoding.html (русский вариант)
* https://hal.inria.fr/hal-02263116/document (интересная статья)
* https://zenodo.org/record/3550780/files/Report_Nazerke_Seidan.pdf (с картинками)
